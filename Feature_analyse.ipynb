{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, ujson, json, pandas as pd, numpy as np, matplotlib.pyplot as plt, math\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from Feature.common import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 筛选 feature\n",
    "\n",
    "## 检查缺失值情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = cPickle.load(open('raw_feature.dat', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 用 20181016 的数据(有问题的数据)\n",
    "保留输出不运行！！\n",
    "for col in raw_df.columns:\n",
    "    missing = len(raw_df) - np.count_nonzero( raw_df[col].isnull().values)\n",
    "    mis_perc = 100 - float(missing) / len(raw_df) * 100\n",
    "    \n",
    "    if mis_perc > 50:\n",
    "        print (\"{miss} %\\t {col}\".format( col=col,miss=round(mis_perc,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用20180901的数据\n",
    "print('missing ratio:\\n')\n",
    "for col in raw_df.columns:\n",
    "    missing = np.count_nonzero( raw_df[col].isnull().values)\n",
    "    mis_perc = float(missing) / len(raw_df) * 100\n",
    "    \n",
    "    if mis_perc :\n",
    "        print (\"{miss} %\\t {col}\".format(col=col,miss=round(mis_perc,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">后一个cell 计算出的missing ratio 是基于 20181016日算的，前一个cell算的是20180901. 能明显看出，后者 push_ 相关feature缺省更为严重，这是因为系统bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">剔除除了push以外的相关缺省严重的 feature。设 threshold = 50%。缺省一半以上的feature, 除了 push_相关 feature 都扔。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## discard unqiue columns\n",
    "\n",
    "> 筛选 unqiue value 太多的，直接扔。筛选方差不大的，直接扔。最后 impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = cPickle.load(open('raw_feature.dat', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop missing ratio 大的feature以后的数据：\n",
    "unique_cols = []\n",
    "\n",
    "for col in raw_df.columns:\n",
    "    if isinstance( raw_df[col][0], dict) or isinstance(raw_df[col][0], list):\n",
    "        continue\n",
    "    \n",
    "    values = raw_df[col]\n",
    "    unique_values = [i for i in values if i != None and i != '']\n",
    "    \n",
    "    if unique_values:\n",
    "        unique_perct = float(len(set(unique_values)))/len(unique_values)*100\n",
    "    \n",
    "        if unique_perct > 20:\n",
    "            print (\"{col}: \\t\\t{miss}%\".format(col=col,miss=round(unique_perct,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "暂且保留：response_timestamp，想做 normalizing, scaling。 其他三个feature，丢～"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## discard var ->0\n",
    "> 筛选方差， 方差趋近于零的，丢～"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = cPickle.load(open('raw_feature.dat', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 找到所有 numerical cols\n",
    "newdf = raw_df.select_dtypes(include=numerics)\n",
    "\n",
    "for c in newdf.columns:\n",
    "    var = np.var( newdf[c].values )\n",
    "    \n",
    "    if var < 3:\n",
    "        print (\"{var}\\t, {col}\".format(var = round(var, 2), col = c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "丢方差太小的： evergreen_confidence, no_of_videos (趋近于0)\n",
    "\n",
    "'spam_word_count' 看起来怪怪得， 研究一下它的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature 相关性(working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cols = []\n",
    "\n",
    "for i in raw_df.columns:\n",
    "    if isinstance( raw_df[i].)\n",
    "\n",
    "raw_df.to_csv('excel_explore.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_feature_value_by_label(df, col):\n",
    "    values_label_dict = defaultdict(list)\n",
    "    \n",
    "    for label, feature_value in zip( df['label'], df[col] ):\n",
    "        values_label_dict[feature_value].append(label)\n",
    "\n",
    "    return values_label_dict\n",
    "\n",
    "def draw_label_log_distribution_by_feature( df, col, log = True, width = 1, perctg = True):\n",
    "    values_label_dict = split_feature_value_by_label(df, col)\n",
    "    \n",
    "    positive_label_count = []\n",
    "    negatie_label_count = []\n",
    "    feature_value = []\n",
    "    pos_perctg = []\n",
    "    \n",
    "    for x,y in values_label_dict.items():\n",
    "        N = len(y)\n",
    "        p = sum(y)\n",
    "        n = N - p\n",
    "        \n",
    "        if log:\n",
    "            positive_label_count.append( math.log(p+1) )\n",
    "            negatie_label_count.append( math.log(n+1) ) \n",
    "            pos_perctg.append( math.log(p/N*100+1) )\n",
    "            plt.ylabel('log count')\n",
    "        else:\n",
    "            positive_label_count.append( p )\n",
    "            negatie_label_count.append( n )\n",
    "            pos_perctg.append( float(p)/(p+n)*20000)\n",
    "            plt.ylabel('count')\n",
    "        feature_value.append(x)\n",
    "\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    width = 1.0/len(pos_perctg)\n",
    "    if perctg:\n",
    "        plt.bar( np.arange(len(pos_perctg))+ width, \\\n",
    "        pos_perctg, \n",
    "        width = 0.2*width, \n",
    "        label = 'pos_%', \n",
    "        color = 'black')\n",
    "    else:\n",
    "        plt.bar( np.arange(len(positive_label_count)), \\\n",
    "                positive_label_count, \\\n",
    "                width = 0.2*width, \\\n",
    "                label = 'positive', \\\n",
    "                color = 'red')\n",
    "        plt.bar( np.arange(len(positive_label_count))+ width, \\\n",
    "                negatie_label_count, \n",
    "                width = 0.2*width, \n",
    "                label = 'negative', \n",
    "                color = 'green')\n",
    "        \n",
    "    plt.title( str(col))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return feature_value, pos_perctg, positive_label_count, negatie_label_count\n",
    "\n",
    "# def draw_label_perctg_by_feature(df, col, log = True):\n",
    "#     ax = plt.subplot(1,1,1)\n",
    "#     plt.plot( range(len(count)), count, '--*' )\n",
    "#     ax.xaxis.set_major_locator( MultipleLocator(3))\n",
    "#     plt.xlabel('app_language')\n",
    "#     plt.ylabel('number of users')\n",
    "#     plt.show()\n",
    "\n",
    "draw_label_log_distribution_by_feature( raw_df, 'app_language', log = False, perctg=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 以下feature在各个class 中分布近似一致，不是显著特征：\n",
    "\n",
    "language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in raw_df.columns[:5]:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode label\n",
    "\n",
    "> 将supervised keywords 啥的，两两配对，计算 similarity\n",
    "\n",
    "raw feature 已经减到了 105"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理 feature 是 dict的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = cPickle.load(open('raw_feature.dat', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 42852)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_df.columns), len(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'body_addons',\n",
       " u'category_v2_score',\n",
       " u'disgusting_scores',\n",
       " u'exp_scores',\n",
       " u'head_addons',\n",
       " u'image_mscv_scores',\n",
       " u'image_nsfw_scores',\n",
       " u'key_entities',\n",
       " u'key_entities_v2',\n",
       " u'key_entities_v2_hash',\n",
       " u'keywords',\n",
       " u'keywords_tag',\n",
       " u'keywords_v2',\n",
       " u'max_disgusting_scores',\n",
       " u'nl_category',\n",
       " u'nl_domain',\n",
       " u'nl_keywords',\n",
       " u'nl_subcategory',\n",
       " u'nl_supervised_keywords',\n",
       " u'nl_title_keywords',\n",
       " u'nl_topic',\n",
       " u'nl_topic2048',\n",
       " u'nl_topic256',\n",
       " u'nl_topic64',\n",
       " u'pictures',\n",
       " u'push_category',\n",
       " u'push_domain',\n",
       " u'push_keywords',\n",
       " u'push_subcategory',\n",
       " u'push_supervised_keywords',\n",
       " u'push_title_keywords',\n",
       " u'push_topic',\n",
       " u'push_topic2048',\n",
       " u'push_topic256',\n",
       " u'push_topic64',\n",
       " u'supervised_keywords',\n",
       " u'supervised_keywords_v2',\n",
       " u'supervised_keywords_v2_origin',\n",
       " u'thumbnail',\n",
       " u'title_keywords',\n",
       " u'topic',\n",
       " u'topic2048',\n",
       " u'topic256',\n",
       " u'topic64',\n",
       " u'topic_v2']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_features = []\n",
    "\n",
    "for c in raw_df.columns:\n",
    "    if c not in numerics and (isinstance(raw_df[c][0], list) or isinstance(raw_df[c][0], dict)):\n",
    "        dict_features.append(c)\n",
    "\n",
    "dict_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 发现有些 feature 压根没有值， 丢～\n",
    "\n",
    "body_addons\n",
    "\n",
    "> 有些有用的dict，值展开，并且放个 others 类别\n",
    "\n",
    "category_v2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23,\n",
       " {u'Accident',\n",
       "  u'Art&Design',\n",
       "  u'Auto',\n",
       "  u'Business',\n",
       "  u'Crime',\n",
       "  u'Education',\n",
       "  u'Fashion&Beauty',\n",
       "  u'Food',\n",
       "  u'Gaming',\n",
       "  u'Health',\n",
       "  u'Home&Garden',\n",
       "  u'News_Entertainment',\n",
       "  u'News_Politics',\n",
       "  u'News_Sports',\n",
       "  u'Others_Natural_Disaster',\n",
       "  u'Others_Plane_Crash',\n",
       "  u'Others_Terrorism',\n",
       "  u'Pet_Animals',\n",
       "  u'Prose',\n",
       "  u'Religion',\n",
       "  u'Science',\n",
       "  u'Technology',\n",
       "  u'Travel'})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = []\n",
    "for value in raw_df['category_v2_score']:\n",
    "        if value:\n",
    "            values.extend(value)\n",
    "len(set(values)), set(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDoNext: 应该单独写一个函数，把所有dict value展开？如果user, context之间有对应关系的，就算各种similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "216px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
